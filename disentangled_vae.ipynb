{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aiml4it/anaconda/3-5.2.0-generic/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/aiml4it/anaconda/3-5.2.0-generic/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/opt/aiml4it/anaconda/3-5.2.0-generic/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/aiml4it/anaconda/3-5.2.0-generic/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/opt/aiml4it/anaconda/3-5.2.0-generic/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/aiml4it/anaconda/3-5.2.0-generic/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from scipy.misc import imsave\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.utils import plot_model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 6\n",
    "max_iterations = 6*6\n",
    "batch_size = 30\n",
    "original_dim = 36\n",
    "intermediate_dim = 30\n",
    "latent_dim = 15\n",
    "epochs = 100\n",
    "input_shape = (original_dim, )\n",
    "epsilon_std = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_divide_data(x,i,h,w):\n",
    "    if i <= max_iterations:\n",
    "        if h != 0 or w != 0 :\n",
    "            random_split = random.randint(0,1) # choose between horizontally and vertically\n",
    "            random_pos = random.randint(0,min(h,w)) # it starts from 1 otherwise we will have a lot of grids with just value 0 all over it            \n",
    "            #print('random_split', random_split)\n",
    "            #print('random_pos', random_pos)\n",
    "            if random_split == 0 :# vertically case\n",
    "                #fill the cells\n",
    "                x[:h,random_pos:w] = i\n",
    "                #print('x',x)\n",
    "                return recur_divide_data(x,i+1,h,random_pos)\n",
    "            else:\n",
    "                #fill the cells\n",
    "                x[random_pos:h,:w] = i\n",
    "                #print('x',x)\n",
    "                return recur_divide_data(x,i+1,random_pos,w)\n",
    "        else:\n",
    "            #print('when h =0 and w = 0 i=', i)\n",
    "            #x[h,w] = i\n",
    "            return\n",
    "    else:\n",
    "        return\n",
    "    #if (x == np.zeros(shape=(DIM,DIM))) and (i == 3): # if in 3 attemtps there were the position is always zero\n",
    "     #   x = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[1,1,1,1,1,1],[1,1,1,1,1,1],[1,1,1,1,1,1]])\n",
    "     #   return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_set(dim):\n",
    "    x_total = []\n",
    "    x_unique = []\n",
    "    #since we remove the case where it is filled with one value, we have to add it manually\n",
    "    x_total.append(np.zeros(shape=(dim,dim)).flatten())\n",
    "    for i in range(30000):\n",
    "        x = np.zeros(shape=(dim,dim))\n",
    "        recur_divide_data(x,0,dim,dim)\n",
    "        #if ((x != np.zeros(shape=(dim,dim))).all()) and ((x != np.ones(shape=(dim,dim))).all()):\n",
    "        x_total.append(x.flatten())\n",
    "    x_total = np.array(x_total)\n",
    "    #to get only unique values out of the data\n",
    "    unique_rows = np.unique(x_total, axis=0)\n",
    "    return unique_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generate_training_set(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the training index so it can be divided by the batch size so we won't have errors in training\n",
    "if x.shape[0] % batch_size != 0:\n",
    "    training_index = int(x.shape[0] / batch_size)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4440"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[0:training_index-900,]\n",
    "x_test = x[training_index-900:training_index,]\n",
    "x_train = x_train.astype('float32') / max_iterations\n",
    "x_test = x_test.astype('float32') / max_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the latent representation vectors !!\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(models,\n",
    "\n",
    "                 data,\n",
    "\n",
    "                 batch_size=batch_size,\n",
    "\n",
    "                 model_name=\"vae\"):\n",
    "\n",
    "    encoder, decoder = models\n",
    "\n",
    "    x_test, _ = data\n",
    "\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,batch_size=batch_size)\n",
    "    x_decoded = decoder.predict(z_mean)\n",
    "    \n",
    "    combined_data = np.array([x_test,x_decoded])\n",
    "    #Get the min and max of all your data\n",
    "    _min, _max = np.amin(combined_data), np.amax(combined_data)\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(40, 8))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(DIM, DIM), cmap=plt.cm.hsv, vmin = _min, vmax = _max)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(x_decoded[i].reshape(DIM, DIM), cmap=plt.cm.hsv, vmin = _min, vmax = _max)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model = encoder + decoder\n",
    "\n",
    "# build encoder model\n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reparameterization trick to push the sampling out as input\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 36)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 30)           1110        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 15)           465         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 15)           465         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 15)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,040\n",
      "Trainable params: 2,040\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate encoder model\n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "encoder.summary()\n",
    "\n",
    "plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decoder model\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 30)                480       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 36)                1116      \n",
      "=================================================================\n",
      "Total params: 1,596\n",
      "Trainable params: 1,596\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate decoder model\n",
    "\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "decoder.summary()\n",
    "\n",
    "plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 15), (None, 15),  2040      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 36)                1596      \n",
      "=================================================================\n",
      "Total params: 3,636\n",
      "Trainable params: 3,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3540 samples, validate on 900 samples\n",
      "Epoch 1/100\n",
      "3540/3540 [==============================] - 1s 226us/step - loss: 16.6234 - val_loss: 10.1805\n",
      "Epoch 2/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 7.7887 - val_loss: 8.1381\n",
      "Epoch 3/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 7.1144 - val_loss: 7.8374\n",
      "Epoch 4/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.9705 - val_loss: 7.7567\n",
      "Epoch 5/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.9202 - val_loss: 7.7155\n",
      "Epoch 6/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.8809 - val_loss: 7.6585\n",
      "Epoch 7/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.8635 - val_loss: 7.6371\n",
      "Epoch 8/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.8366 - val_loss: 7.5992\n",
      "Epoch 9/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.7949 - val_loss: 7.5553\n",
      "Epoch 10/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.7457 - val_loss: 7.5162\n",
      "Epoch 11/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.7105 - val_loss: 7.4947\n",
      "Epoch 12/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.6915 - val_loss: 7.4934\n",
      "Epoch 13/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.6843 - val_loss: 7.4944\n",
      "Epoch 14/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.6783 - val_loss: 7.4889\n",
      "Epoch 15/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.6637 - val_loss: 7.4462\n",
      "Epoch 16/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.6320 - val_loss: 7.4220\n",
      "Epoch 17/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.6169 - val_loss: 7.4183\n",
      "Epoch 18/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.6095 - val_loss: 7.4056\n",
      "Epoch 19/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.6053 - val_loss: 7.4045\n",
      "Epoch 20/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.6006 - val_loss: 7.3957\n",
      "Epoch 21/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5970 - val_loss: 7.3879\n",
      "Epoch 22/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5934 - val_loss: 7.3855\n",
      "Epoch 23/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5913 - val_loss: 7.3716\n",
      "Epoch 24/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5885 - val_loss: 7.3809\n",
      "Epoch 25/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5859 - val_loss: 7.3720\n",
      "Epoch 26/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5868 - val_loss: 7.3766\n",
      "Epoch 27/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5851 - val_loss: 7.3621\n",
      "Epoch 28/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5812 - val_loss: 7.3637\n",
      "Epoch 29/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5792 - val_loss: 7.3588\n",
      "Epoch 30/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5790 - val_loss: 7.3553\n",
      "Epoch 31/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5778 - val_loss: 7.3499\n",
      "Epoch 32/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5769 - val_loss: 7.3498\n",
      "Epoch 33/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5744 - val_loss: 7.3478\n",
      "Epoch 34/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5731 - val_loss: 7.3495\n",
      "Epoch 35/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5717 - val_loss: 7.3562\n",
      "Epoch 36/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5700 - val_loss: 7.3477\n",
      "Epoch 37/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5684 - val_loss: 7.3415\n",
      "Epoch 38/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5645 - val_loss: 7.3390\n",
      "Epoch 39/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5633 - val_loss: 7.3387\n",
      "Epoch 40/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5613 - val_loss: 7.3323\n",
      "Epoch 41/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5596 - val_loss: 7.3317\n",
      "Epoch 42/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5584 - val_loss: 7.3244\n",
      "Epoch 43/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5573 - val_loss: 7.3282\n",
      "Epoch 44/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5554 - val_loss: 7.3238\n",
      "Epoch 45/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5543 - val_loss: 7.3312\n",
      "Epoch 46/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5533 - val_loss: 7.3191\n",
      "Epoch 47/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5497 - val_loss: 7.3257\n",
      "Epoch 48/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5518 - val_loss: 7.3184\n",
      "Epoch 49/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5485 - val_loss: 7.3168\n",
      "Epoch 50/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5484 - val_loss: 7.3144\n",
      "Epoch 51/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5488 - val_loss: 7.3171\n",
      "Epoch 52/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5477 - val_loss: 7.3176\n",
      "Epoch 53/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5477 - val_loss: 7.3117\n",
      "Epoch 54/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5446 - val_loss: 7.3080\n",
      "Epoch 55/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5441 - val_loss: 7.3104\n",
      "Epoch 56/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5432 - val_loss: 7.3032\n",
      "Epoch 57/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5426 - val_loss: 7.3042\n",
      "Epoch 58/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5432 - val_loss: 7.3055\n",
      "Epoch 59/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5442 - val_loss: 7.3047\n",
      "Epoch 60/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5395 - val_loss: 7.3031\n",
      "Epoch 61/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5392 - val_loss: 7.2987\n",
      "Epoch 62/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5407 - val_loss: 7.3009\n",
      "Epoch 63/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5386 - val_loss: 7.2988\n",
      "Epoch 64/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5366 - val_loss: 7.3014\n",
      "Epoch 65/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5376 - val_loss: 7.3006\n",
      "Epoch 66/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5370 - val_loss: 7.2972\n",
      "Epoch 67/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5364 - val_loss: 7.3002\n",
      "Epoch 68/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5363 - val_loss: 7.3019\n",
      "Epoch 69/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5361 - val_loss: 7.2931\n",
      "Epoch 70/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5329 - val_loss: 7.3003\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5316 - val_loss: 7.2946\n",
      "Epoch 72/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5313 - val_loss: 7.2975\n",
      "Epoch 73/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5293 - val_loss: 7.2945\n",
      "Epoch 74/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5306 - val_loss: 7.2963\n",
      "Epoch 75/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5315 - val_loss: 7.2935\n",
      "Epoch 76/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5301 - val_loss: 7.2870\n",
      "Epoch 77/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5307 - val_loss: 7.2887\n",
      "Epoch 78/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5284 - val_loss: 7.2903\n",
      "Epoch 79/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5261 - val_loss: 7.2830\n",
      "Epoch 80/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5285 - val_loss: 7.2892\n",
      "Epoch 81/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5254 - val_loss: 7.2850\n",
      "Epoch 82/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5242 - val_loss: 7.2891\n",
      "Epoch 83/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5244 - val_loss: 7.2879\n",
      "Epoch 84/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5208 - val_loss: 7.2854\n",
      "Epoch 85/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5236 - val_loss: 7.2883\n",
      "Epoch 86/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5246 - val_loss: 7.2803\n",
      "Epoch 87/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5238 - val_loss: 7.2879\n",
      "Epoch 88/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5215 - val_loss: 7.2849\n",
      "Epoch 89/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5217 - val_loss: 7.2876\n",
      "Epoch 90/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5183 - val_loss: 7.2836\n",
      "Epoch 91/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5206 - val_loss: 7.2771\n",
      "Epoch 92/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5188 - val_loss: 7.2772\n",
      "Epoch 93/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5197 - val_loss: 7.2810\n",
      "Epoch 94/100\n",
      "3540/3540 [==============================] - 0s 42us/step - loss: 6.5149 - val_loss: 7.2772\n",
      "Epoch 95/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5153 - val_loss: 7.2817\n",
      "Epoch 96/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5181 - val_loss: 7.2810\n",
      "Epoch 97/100\n",
      "3540/3540 [==============================] - 0s 43us/step - loss: 6.5145 - val_loss: 7.2808\n",
      "Epoch 98/100\n",
      "3540/3540 [==============================] - 0s 44us/step - loss: 6.5167 - val_loss: 7.2771\n",
      "Epoch 99/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5156 - val_loss: 7.2811\n",
      "Epoch 100/100\n",
      "3540/3540 [==============================] - 0s 41us/step - loss: 6.5140 - val_loss: 7.2701\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = (encoder, decoder)\n",
    "\n",
    "data = (x_test, _)\n",
    "\n",
    "reconstruction_loss = binary_crossentropy(inputs,outputs)\n",
    "\n",
    "reconstruction_loss *= original_dim\n",
    "\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "\n",
    "kl_loss *= -0.5\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "vae.summary()\n",
    "\n",
    "plot_model(vae,\n",
    "\n",
    "           to_file='vae_mlp.png',\n",
    "\n",
    "           show_shapes=True)\n",
    "\n",
    "vae.fit(x_train,\n",
    "\n",
    "        epochs=epochs,\n",
    "\n",
    "        batch_size=batch_size,\n",
    "\n",
    "        validation_data=(x_test, None))\n",
    "\n",
    "vae.save_weights('vae_mlp_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x576 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(models,\n",
    "\n",
    "             data,\n",
    "\n",
    "             batch_size=batch_size,\n",
    "\n",
    "             model_name=\"vae_mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
